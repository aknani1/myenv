Folder Structure
--------------------------------------------------
app/
    camera.py
    routes.py
    __init__.py
    statics/
        css/
            main.css
    templates/
        index.html
    __pycache__/
        camera.cpython-310.pyc
        camera.cpython-311.pyc
        camera.cpython-312.pyc
        camera.cpython-38.pyc
        init.cpython-38.pyc
        routes.cpython-310.pyc
        routes.cpython-311.pyc
        routes.cpython-312.pyc
        routes.cpython-38.pyc
        __init__.cpython-310.pyc
        __init__.cpython-311.pyc
        __init__.cpython-312.pyc
        __init__.cpython-313.pyc
        __init__.cpython-38.pyc


File Contents
--------------------------------------------------


C:\Users\aknani\myenv\app\camera.py
File type: .py
import pyrealsense2 as rs
import numpy as np
import cv2
import base64
from app import socketio
import time

# Store standard config and pipeline at module level
pipeline = rs.pipeline()
config = rs.config()

# Track streaming state
streaming = {"status": True}
exposure_value = {"status": 80}
# Keep separate current settings for color and depth
# e.g., resolution and fps
current_settings = {
    "color": {
        "width": 640,
        "height": 360,
        "fps": 30
    },
    "depth": {
        "width": 640,
        "height": 360,
        "fps": 30
    }
}

# Track last frame times for displayed FPS calculation
last_color_time = 0.0
last_depth_time = 0.0
displayed_color_fps = 0.0
displayed_depth_fps = 0.0

# Metadata toggles
metadata_toggles = {
    "rgb": False,
    "depth": False
}
AVAILABLE_METADATA = [
    (rs.frame_metadata_value.frame_counter,       "Frame Counter"),
    (rs.frame_metadata_value.sensor_timestamp,    "Sensor Timestamp"),
    (rs.frame_metadata_value.backend_timestamp,   "Backend Timestamp"),
    (rs.frame_metadata_value.actual_fps,          "Actual FPS"),
    (rs.frame_metadata_value.auto_exposure,       "Auto Exposure"),
    (rs.frame_metadata_value.white_balance,       "White Balance"),
    (rs.frame_metadata_value.brightness,          "Brightness"),
    (rs.frame_metadata_value.contrast,            "Contrast"),
    (rs.frame_metadata_value.saturation,          "Saturation"),
    (rs.frame_metadata_value.sharpness,           "Sharpness"),
]


def stop_generating_frames():
    global streaming, pipeline
    streaming["status"] = False
    try:
        pipeline.stop()
    except Exception:
        pass


def configure_pipeline():
    """
    Applies the global current_settings to the pipeline config,
    stopping the pipeline if running, then re-starting it.
    """
    global pipeline, config, streaming

    # If streaming is active, stop first
    if streaming["status"]:
        stop_generating_frames()

    # Clear previous config
    config.disable_all_streams()

    # Enable color stream with the updated resolution/fps
    c = current_settings["color"]
    config.enable_stream(
        rs.stream.color,
        c["width"],
        c["height"],
        rs.format.bgr8,
        c["fps"]
    )

    # Enable depth stream likewise
    d = current_settings["depth"]
    config.enable_stream(
        rs.stream.depth,
        d["width"],
        d["height"],
        rs.format.z16,
        d["fps"]
    )

    profile = pipeline.start(config)
    streaming["status"] = True
    print("[Pipeline] Started with new configuration:", current_settings)
    return profile


def gather_metadata_and_profile_info(frame):
    """
    Gather hardware fps from metadata if available, plus resolution, etc.
    """
    lines = []
    # 1) Possibly read actual_fps if supported
    if frame.supports_frame_metadata(rs.frame_metadata_value.actual_fps):
        hw_fps = frame.get_frame_metadata(rs.frame_metadata_value.actual_fps)
        lines.append(f"Actual FPS: {hw_fps}")

    # 2) Additional metadata fields as desired...
    # e.g., frame_number, sensor_timestamp, etc.
    if frame.supports_frame_metadata(rs.frame_metadata_value.frame_counter):
        fc = frame.get_frame_metadata(rs.frame_metadata_value.frame_counter)
        lines.append(f"Frame Count: {fc}")

    # 3) Profile info
    profile = rs.video_stream_profile(frame.get_profile())
    w = profile.width()
    h = profile.height()
    fmt = profile.format()
    lines.append(f"Resolution: {w}x{h}")
    lines.append(f"Pixel Format: {fmt}")

    return lines

def overlay_in_top_left(image, lines, text_color=(0, 255, 0)):
    """
    Draws a bounding box of text lines in the top-left corner
    without letting it go offscreen.
    """
    if not lines:
        return

    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.6
    thickness = 2
    line_height = 25
    margin = 5

    # Determine bounding box size
    max_width = 0
    for line in lines:
        (text_size, _) = cv2.getTextSize(line, font, font_scale, thickness)
        if text_size[0] > max_width:
            max_width = text_size[0]

    box_width = max_width + (margin * 2)
    box_height = (line_height * len(lines)) + (margin * 2)

    x = 150
    y = 15

    # Clamping
    if x + box_width > image.shape[1]:
        x = max(0, image.shape[1] - box_width - 10)
    if y + box_height > image.shape[0]:
        y = max(0, image.shape[0] - box_height - 10)

    
    text_y = y + margin + line_height - 5
    for line in lines:
        cv2.putText(
            image,
            line,
            (x + margin, text_y),
            font,
            font_scale,
            text_color,
            thickness
        )
        text_y += line_height
        
        
        
def generate_frames():
    """
    Continuously yield frames from the pipeline with metadata overlays,
    plus displayed FPS.
    """
    global last_color_time, displayed_color_fps
    global last_depth_time, displayed_depth_fps
    global color_sensor

    profile = configure_pipeline()
    device = profile.get_device()
    sensors = device.query_sensors()

    for sensor in sensors:
        if sensor.get_info(rs.camera_info.name) == "RGB Camera":
            color_sensor = sensor
            break

    if color_sensor is None:
        raise RuntimeError("Color sensor not found!")

    # Step 4: Disable auto-exposure
    color_sensor.set_option(rs.option.enable_auto_exposure, 0)

    # Step 5: Set manual exposure (e.g., 1000 microseconds)
    #exposure_value = 1000  # Adjust this value as needed
    print(f"Manual exposure set to {exposure_value} microseconds.")


    try:
        while streaming["status"]:
            # Wait for frames; if pipeline is stopped externally, it might error
            try:
                frameset = pipeline.wait_for_frames()
            except Exception as e:
                print("[Error waiting for frames]:", e)
                break

            color_frame = frameset.get_color_frame()
            depth_frame = frameset.get_depth_frame()

            if not color_frame or not depth_frame:
                continue

            # Compute displayed FPS color
            now_c = time.time()
            if last_color_time != 0:
                dt_c = now_c - last_color_time
                if dt_c > 0:
                    displayed_color_fps = 1.0 / dt_c
            last_color_time = now_c

            # Compute displayed FPS depth
            now_d = time.time()
            if last_depth_time != 0:
                dt_d = now_d - last_depth_time
                if dt_d > 0:
                    displayed_depth_fps = 1.0 / dt_d
            last_depth_time = now_d

            color_image = np.asanyarray(color_frame.get_data())
            depth_colorized_frame = rs.colorizer().colorize(depth_frame)
            depth_image = np.asanyarray(depth_colorized_frame.get_data())

            # If metadata is toggled, gather lines & overlay
            if metadata_toggles["rgb"]:
                lines_rgb = gather_metadata_and_profile_info(color_frame)
                lines_rgb.append(f"Displayed FPS: {displayed_color_fps:.1f}")
                overlay_in_top_left(color_image, lines_rgb, text_color=(0, 255, 0))

            if metadata_toggles["depth"]:
                lines_depth = gather_metadata_and_profile_info(depth_frame)
                lines_depth.append(f"Displayed FPS: {displayed_depth_fps:.1f}")
                overlay_in_top_left(depth_image, lines_depth, text_color=(255, 0, 0))

            _, color_buf = cv2.imencode('.jpg', color_image)
            _, depth_buf = cv2.imencode('.jpg', depth_image)
            color_frame_encoded = base64.b64encode(color_buf).decode('utf-8')
            depth_frame_encoded = base64.b64encode(depth_buf).decode('utf-8')

            yield {"color": color_frame_encoded, "depth": depth_frame_encoded}
        stop_generating_frames()
    finally:
        stop_generating_frames()
        
def change_exposure():
    color_sensor.set_option(rs.option.exposure, exposure_value["status"])


def toggle_metadata(module):
    if module in metadata_toggles:
        metadata_toggles[module] = not metadata_toggles[module]

--------------------------------------------------
File End
--------------------------------------------------


C:\Users\aknani\myenv\app\routes.py
File type: .py
from flask import render_template, current_app,request,jsonify
from app import socketio
import pyrealsense2 as rs
from .camera import (
    configure_pipeline, generate_frames, toggle_metadata,
    stop_generating_frames, streaming, current_settings,exposure_value,change_exposure
)


def init_routes(app):
    @app.route('/')
    def index():
        return render_template('index.html')
    @app.route('/api/configure', methods=['POST'])
    def configure():
        """
        Example: { "module": "rgb", "resolution": "1280x720", "frame_rate": 15 }
        """
        try:
            data = request.json
            module = data.get('module')  # "rgb" or "depth"
            resolution = data.get('resolution')  # e.g. "1280x720"
            frame_rate = data.get('frame_rate')  # e.g. 15
            if not module or not resolution or not frame_rate:
                return jsonify({"error": "Missing data"}), 400

            width, height = map(int, resolution.split('x'))

            if module == "rgb":
                current_settings["color"]["width"] = width
                current_settings["color"]["height"] = height
                current_settings["color"]["fps"] = int(frame_rate)
            elif module == "depth":
                current_settings["depth"]["width"] = width
                current_settings["depth"]["height"] = height
                current_settings["depth"]["fps"] = int(frame_rate)
            else:
                return jsonify({"error": "Invalid module"}), 400

            # Now reconfigure pipeline
            configure_pipeline()
            return jsonify({
                "message": f"{module.capitalize()} updated to {resolution} @ {frame_rate} FPS"
            }), 200

        except Exception as e:
            print("Error in /api/configure:", e)
            return jsonify({"error": str(e)}), 500

    @app.route('/api/toggle_metadata', methods=['POST'])
    def toggle_metadata_endpoint():
        data = request.json
        module = data.get('module')
        if module not in ['rgb', 'depth']:
            return jsonify({"error": "Invalid module"}), 400
        
        toggle_metadata(module)
        return jsonify({"message": f"{module.capitalize()} metadata toggled", "status": toggle_metadata[module]})

      
        
        
    @app.route('/api/stop_stream', methods=['POST'])
    def stop_stream():
        stop_generating_frames()
        return jsonify({"message": "Streaming stopped"})
    @socketio.on('connect')
    def handle_connect():
        print('Client connected')

    @socketio.on('start_stream')
    def start_stream():
        print("Received start_stream event from client.")
        for frame in generate_frames():
            socketio.emit('video_frame', frame)


    @app.route('/api/exposure', methods=['POST'])
    def update_exposure():
        try:
            # Parse the JSON payload from the client
            data = request.json
            module = data.get('module')
            req_exposure_value = int(data.get('exposure'))  # Exposure value (e.g., 8500)
            
            print(data)
            # Validate input
            if not module or exposure_value is None:
                return jsonify({"error": "Invalid input"}), 400

            # if module == 'depth':
            #     # Ensure depth sensor exists
            #     if len(sensors) < 1:
            #         return jsonify({"error": "Depth sensor not found"}), 500

            #     depth_sensor = sensors[0]  # Assuming depth is the first sensor
            #     if rs.option.exposure in depth_sensor.get_supported_options():
            #         depth_sensor.set_option(rs.option.exposure, exposure_value)
            #         print(f"Depth Module exposure updated to {exposure_value}")
            #     else:
            #         return jsonify({"error": "Exposure option not supported for Depth Module"}), 400

            if module == 'rgb':
                # Ensure RGB sensor exists
                exposure_value["status"] = req_exposure_value
                change_exposure()

            else:
                return jsonify({"error": "Invalid module"}), 400

            return jsonify({
                "message": f"{module.capitalize()} Module exposure updated",
                "exposure": exposure_value
            }), 200

        except Exception as e:
            print(f"Error: {e}")
            return jsonify({"error": str(e)}), 500 


# Call this function in __init__.py after creating the app
# init_routes(current_app)

--------------------------------------------------
File End
--------------------------------------------------


C:\Users\aknani\myenv\app\__init__.py
File type: .py
from flask import Flask
from flask_cors import CORS
from flask_socketio import SocketIO
import time

app = Flask(__name__)
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*")

def create_app():
    app.config.from_object('config.Config')

    socketio.init_app(app)

    with app.app_context():
        from app import routes
        from .routes import init_routes
        init_routes(app)

    return app


--------------------------------------------------
File End
--------------------------------------------------


C:\Users\aknani\myenv\app\statics\css\main.css
File type: .css
body {
    font-family: Arial, sans-serif;
    text-align: center;
}
h1 {
    color: #333;
}
#video-stream {
    max-width: 100%;
    height: auto;
}

--------------------------------------------------
File End
--------------------------------------------------


C:\Users\aknani\myenv\app\templates\index.html
File type: .html
<!DOCTYPE html>
<html>
<head>
    <title>RealSense Camera Viewer</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
</head>
<body>
    <h1>RealSense Camera Viewer</h1>
    <img id="video-stream" src="">
    <script>
        var socket = io.connect('http://' + document.domain + ':' + location.port);
        socket.on('data', function(data) {
            document.getElementById('video-stream').src = 'data:image/jpeg;base64,' + data.image;
        });
    </script>
</body>
</html>

--------------------------------------------------
File End
--------------------------------------------------


C:\Users\aknani\myenv\app\__pycache__\camera.cpython-38.pyc
File type: .pyc
U

    è Kg÷  ã                   @   s8   d dl Zd dlZd dlZd dlZd dlmZ dd„ ZdS )é    N)Úsocketioc                  C   sž   t  ¡ } t  ¡ }| t jjddt jjd¡ |  |¡ zZ|  
¡ }| ¡ }|sLq6t 
| ¡ ¡}t d|¡\}}t |¡ d¡}t dd|i¡ q6W 5 |  	¡  X d S )Ni€  ià  é   z.jpgzutf-8ÚframeÚimage)ÚrsÚpipelineÚconfigZ
enable_streamÚstreamÚcolorÚformatZbgr8ÚstartÚstopZwait_for_framesZget_color_frameÚnpZ
asanyarrayÚget_dataÚcv2ZimencodeÚbase64Ú	b64encodeÚdecoder   Úemit)r   r   ÚframesZcolor_frameZcolor_imageÚretÚbufferr   © r   ú\C:\Users\mayyas\Documents\technion\semester_5\IntelRealSenseProject\WEB_VIEWER\app\camera.pyÚget_realsense_frame   s    
r   )	Zpyrealsense2r   Znumpyr   r   r   Úappr   r   r   r   r   r   Ú<module>   s
   

--------------------------------------------------
File End
--------------------------------------------------


C:\Users\aknani\myenv\app\__pycache__\init.cpython-38.pyc
File type: .pyc
U

    ]Kg  ã                   @   s*   d dl mZ d dlmZ eƒ Zdd„ ZdS )é    )ÚFlask)ÚSocketIOc                  C   s.   t tƒ} | j d¡ t | ¡ ddlm} | S )Nz
config.Configr   )Úroutes)r   Ú__name__ZconfigZfrom_objectÚsocketioZinit_appÚappr   )r   r   © r   úZC:\Users\mayyas\Documents\technion\semester_5\IntelRealSenseProject\WEB_VIEWER\app\init.pyÚ
create_app   s
    
r
   N)Zflaskr   Zflask_socketior   r   r
   r   r   r   r	   Ú<module>   s   

--------------------------------------------------
File End
--------------------------------------------------


C:\Users\aknani\myenv\app\__pycache__\routes.cpython-38.pyc
File type: .pyc
U

    Ú&Kg°  ã                   @   s4   d dl mZmZ d dlmZ ddlmZ dd„ ZdS )é    )Úrender_templateÚcurrent_app)Úsocketioé   )Úget_realsense_framec                 C   s(   |   d¡dd„ ƒ}t d¡dd„ ƒ}d S )Nú/c                   S   s   t dƒS )Nz
index.html)r   © r   r   ú\C:\Users\mayyas\Documents\technion\semester_5\IntelRealSenseProject\WEB_VIEWER\app\routes.pyÚindex   s    zinit_routes.<locals>.indexÚconnectc                   S   s   t  t¡ d S )N)r   Ústart_background_taskr   r   r   r   r	   Úhandle_connect
   s    z#init_routes.<locals>.handle_connect)Úrouter   Úon)Úappr
   r
   r   r   r	   Úinit_routes   s    
r   N)Úflaskr   r   r   r   Zcamerar   r   r   r   r   r	   Ú<module>   s   

--------------------------------------------------
File End
--------------------------------------------------
